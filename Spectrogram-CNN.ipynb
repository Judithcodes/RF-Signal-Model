{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset_full = cPickle.load(open(\"RML2016.10a_dict.dat\",'rb'), encoding='latin1')\n",
    "\n",
    "#snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], dataset_full.keys())))), [1,0])\n",
    "#print(mods)\n",
    "\n",
    "\n",
    "\n",
    "mods = ['BPSK', 'QAM16', 'AM-DSB', 'WBFM']#, 'AM-SSB', 'QPSK']\n",
    "\n",
    "## Filter to consider only 3 modulations (BPSK, QPSK, QAM16) with SNR ranging from 0-18.\n",
    "Xd = {}\n",
    "\n",
    "for mod in mods:\n",
    "    for snr in range(8,20,2):\n",
    "        Xd[(mod,snr)] = dataset_full[(mod,snr)]\n",
    "\n",
    "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
    "print(mods)\n",
    "X = []  \n",
    "lbl = []\n",
    "for mod in mods:\n",
    "    for snr in snrs:\n",
    "        X.append(Xd[(mod,snr)])\n",
    "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
    "X = np.vstack(X)\n",
    "lbl = np.array(lbl)\n",
    "print(lbl)\n",
    "print(X.shape)\n",
    "np.savetxt(\"labels.csv\", lbl, delimiter=\",\", fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a Spectrogram and store it as a numpy array\n",
    "\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "dataset = []\n",
    "filename = \"spectrograms.csv\"\n",
    "f_handle = open(filename, 'ab')\n",
    "\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    \n",
    "    ## Convert the data into complex form\n",
    "    dat = X[i,0,:] + 1j*X[i,1,:]  \n",
    "\n",
    "    # Plot the spctrogram    \n",
    "    plt.figure()\n",
    "    ## reset the figure size\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "    # Set figure width to 2.5 and height to 3\n",
    "    fig_size[0] = 3\n",
    "    fig_size[1] = 2.5\n",
    "    \n",
    "    plt.specgram(dat, NFFT=1024, Fs=1000000)\n",
    "    #plt.title(\"PSD of 'signal' \" + mod )\n",
    "    #plt.xlabel(\"Time\")\n",
    "    #plt.ylabel(\"Frequency\")\n",
    "    axes = plt.gca()\n",
    "    plt.axis('off')\n",
    "    #axes.set_xlim([xmin,xmax])\n",
    "    axes.set_ylim([-200000,200000])\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "\n",
    "    ## Save the color image and reread it as a grayscale image\n",
    "    plt.savefig(\"spect.png\", bbox_inches='tight',pad_inches=-0.8)\n",
    "    img = Image.open('spect.png').convert('L')\n",
    "\n",
    "\n",
    "    ## Store the image as a numpy array\n",
    "    img_as_np = np.asarray(img)\n",
    "    #print(img_as_np.shape)\n",
    "    #img.save('spect_gray.png')\n",
    "    plt.close('all')\n",
    "\n",
    "    dataset.append(img_as_np.flatten())\n",
    "    \n",
    "    \n",
    "    ## Write the dataset into a csv in batches of 5000\n",
    "    if(i%5000 == 0):\n",
    "        dataset = np.array(dataset)\n",
    "        np.savetxt(f_handle, dataset, delimiter=\",\", fmt=\"%3u\")\n",
    "        dataset = []\n",
    "        print(i)\n",
    "\n",
    "#print(dataset)\n",
    "if dataset:\n",
    "    dataset = np.array(dataset)\n",
    "    np.savetxt(f_handle, dataset, delimiter=\",\", fmt=\"%3u\")\n",
    "        \n",
    "    #np.save(f_handle, dataset)\n",
    "    dataset = []\n",
    "    \n",
    "f_handle.close()            \n",
    "\n",
    "\n",
    "print(\"Dataset and labels sucessfully generated and dumped into 'spectrograms.csv' and labels.csv files!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from numpy import genfromtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "img_rows, img_cols = 41, 108\n",
    "nb_classes = 4\n",
    "\n",
    "## Change the modulation labels to numeric labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_encoding = le.fit(lbl)\n",
    "labels_numeric = le.transform(lbl) \n",
    "\n",
    "print(lbl)\n",
    "print(labels_numeric)\n",
    "print(label_encoding)\n",
    "    \n",
    "## Shuffle the data before test-train split    \n",
    "data, Label = shuffle(dataset, labels_numeric, random_state = 2)\n",
    "train_data = [data,Label]\n",
    "    \n",
    "(X,y) = (train_data[0], train_data[1])\n",
    "    \n",
    "## Split data into training and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "X_train = X_train.reshape(X_train.shape[0], img_cols, img_rows, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_cols, img_rows, 1)    \n",
    "\n",
    "#X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "#X_test = X_test.reshape(X_test.shape[0],1,img_rows, img_cols)\n",
    "    \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "    \n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "    \n",
    "#print(X_train)\n",
    "    \n",
    "print('X_train shape: ', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "     \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "i=100\n",
    "plt.imshow(X_train[i,0], interpolation = 'nearest')\n",
    "plt.show()\n",
    "print(\"label: \", Y_train[i,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build the CNN Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "## Set Model Parameters\n",
    "\n",
    "# batch size to train\n",
    "batch_size = 32\n",
    "\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "# number of channels\n",
    "img_channels = 1\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "\n",
    "# Size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "\n",
    "# convolution kernal size\n",
    "nb_conv = 3\n",
    "\n",
    "print(\"test\")\n",
    "\n",
    "model = Sequential()\n",
    "print(\"abc\")\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (nb_conv, nb_conv), padding='valid', input_shape=(img_cols, img_rows,1)))#,img_rows, img_cols)))\n",
    "print(\"0\")\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "print('1')\n",
    "\n",
    "model.add(Convolution2D(nb_filters, (nb_conv, nb_conv)))\n",
    "model.add(Activation('relu'))\n",
    "print(\"2\")\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "print(3)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "print(5)\n",
    "\n",
    "#model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test) )\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Store the test and train data\n",
    "\n",
    "with open('train_x.dat','wb') as train_handle:\n",
    "    np.save(train_handle, X_train)\n",
    "\n",
    "with open('train_y.dat','wb') as train_lbl_handle:\n",
    "    np.save(train_lbl_handle, Y_train)\n",
    "    \n",
    "with open('test_x.dat','wb') as test_handle:    \n",
    "    np.save(test_handle, X_test)\n",
    "\n",
    "with open('test_y.dat','wb') as test_lbl_handle:\n",
    "    np.save(test_lbl_handle, Y_test)\n",
    "\n",
    "train_handle.close()\n",
    "test_handle.close()\n",
    "train_lbl_handle.close()\n",
    "test_lbl_handle.close()\n",
    "\n",
    "## Store the model\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Score the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Test Score: \", score[0])\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
    "conf = np.zeros([nb_classes,nb_classes])\n",
    "confnorm = np.zeros([nb_classes,nb_classes])\n",
    "for i in range(0,X_test.shape[0]):\n",
    "    j = list(Y_test[i,:]).index(1)\n",
    "    k = int(np.argmax(test_Y_hat[i,:]))\n",
    "    conf[j,k] = conf[j,k] + 1\n",
    "for i in range(0,nb_classes):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "plot_confusion_matrix(confnorm, labels=mods)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
